<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>WAVLab</title>
<meta name="description" content="Webpage of Watanabe's Audio and Voice (WAV) Lab
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="/assets/img/favicon.jpeg">

<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

  <script src="/assets/js/theme.js"></script>
  <!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       WAVLab
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
              
            </a>
          </li>

          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/members/">
                Members
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Publications
                
              </a>
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/open_source">
                Open-source
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/sponsors/">
                Sponsors
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/positions/">
                Positions
                
              </a>
          </li>
          
          
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              Activities
              
            </a>
          </li>
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     WAVLab
    </h1>
     <p class="desc">affiliated with @ <a href="https://www.lti.cs.cmu.edu/">LTI/CMU</a>.</p>
  </header>

  <article>
    

    <div class="clearfix">
      <p>This is Watanabe’s Audio and Voice (WAV) Lab at the Language Technologies Institute of Carnegie Mellon University. Our research interests include automatic speech recognition, speech enhancement, spoken language understanding, and machine learning for speech and language processing.</p>

<div class="col-sm mt-3 mt-md-0" style="display:table-cell; vertical-align:middle; text-align:center">
	<a href="https://shinjiwlab.github.io/">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/lab-photo.png" />
    </a>
    <div class="caption">
        Our Lab
    </div>
</div>

    </div>

    
      <div class="news">
  <h2>news</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Sep 13, 2021</th>
          <td>
            
              Our lab has 9 ASRU paper accepted in the ASRU2021. Detailed list is already available in <a href="https://shinjiwlab.github.io/publications/">publication page</a>.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jun 7, 2021</th>
          <td>
            
              Shinji, with Keisuke, Yusuke, and Naoyuki, delivered a tutorial on “Distant Conversational Speech Recognition And Analysis: Recent Advances, And Trends Towards End-To-End Optimization” in ICASSP 2021. Detailed slides can be found <a href="https://github.com/ICASSP2021-tutorial9/Distant_conversational_ASR_and_analysis">here</a>.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jun 3, 2021</th>
          <td>
            
              Our lab has 20 Interspeech paper accepted in the Interspeech2021. Detailed list will be available soon in <a href="https://shinjiwlab.github.io/publications/">publication page</a>.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">May 20, 2021</th>
          <td>
            
              Our lab published 14 ICASSP paper in the up-coming ICASSP2021. Please check <a href="https://shinjiwlab.github.io/publications/">here</a> for details.

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>selected publications</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ASR</abbr>
    
  
  
    
    <abbr class="badge badge-info">Interspeech</abbr>
    
  
  </div>

  <div id="watanabe2018espnet" class="col-sm-8">
    
      <div class="title">ESPnet: End-to-End Speech Processing Toolkit</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://sites.google.com/view/shinjiwatanabe" target="_blank">Shinji Watanabe</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Takaaki Hori,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Shigeki Karita,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tomoki Hayashi,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jiro Nishitoba,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yuya Unno,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nelson Enrique Yalta Soplin,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jahn Heymann,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Matthew Wiesner,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nanxin Chen,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Adithya Renduchintala,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Tsubasa Ochiai
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of Interspeech</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/1804.00015" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      <a href="https://www.isca-speech.org/archive/Interspeech_2018/abstracts/1456.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1456.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/espnet/espnet" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper introduces a new open source platform for end-to-end speech processing named ESPnet. ESPnet mainly focuses on end-to-end automatic speech recognition (ASR), and adopts widely-used dynamic neural network toolkits, Chainer and PyTorch, as a main deep learning engine. ESPnet also follows the Kaldi ASR toolkit style for data processing, feature extraction/format, and recipes to provide a complete setup for speech recognition and other speech processing experiments. This paper explains a major architecture of this software platform, several important functionalities, which differentiate ESPnet from other open source ASR toolkits, and experimental results with major ASR benchmarks.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">SE&ASR</abbr>
    
  
  
    
    <abbr class="badge badge-info">Interspeech</abbr>
    
  
  </div>

  <div id="barker2018fifth" class="col-sm-8">
    
      <div class="title">The Fifth’CHiME’Speech Separation and Recognition Challenge: Dataset, Task and Baselines</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Jon Barker,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://sites.google.com/view/shinjiwatanabe" target="_blank">Shinji Watanabe</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Emmanuel Vincent,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Jan Trmal
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of Interspeech</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">SE</abbr>
    
  
  
    
    <abbr class="badge badge-info">Interspeech</abbr>
    
  
  </div>

  <div id="sell2018diarization" class="col-sm-8">
    
      <div class="title">Diarization is Hard: Some Experiences and Lessons Learned for the JHU Team in the Inaugural DIHARD Challenge.</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Gregory Sell,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  David Snyder,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Alan McCree,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Daniel Garcia-Romero,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jesús Villalba,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Matthew Maciejewski,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Vimal Manohar,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Najim Dehak,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Daniel Povey,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://sites.google.com/view/shinjiwatanabe" target="_blank">Shinji Watanabe</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and  others
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Interspeech</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>
</div>

    

    
    <div class="social">
      <div class="contact-icons">
        




<a href="https://github.com/shinjiwlab" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/wavlab-cmu" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
<a href="https://twitter.com/WavLab" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>









      </div>
      <div class="contact-note"></div>
    </div>
    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021   WAV Lab.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
